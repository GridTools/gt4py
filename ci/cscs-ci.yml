#
# GT4Py - GridTools Framework
#
# Copyright (c) 2014-2024, ETH Zurich
# All rights reserved.
#
# Please, refer to the LICENSE file in the root directory.
# SPDX-License-Identifier: BSD-3-Clause
#

# The build job creates a the base image for the CSCS CI only if the external
# dependencies change. The actual repository is cloned at the test stage.

include:
  - remote: 'https://gitlab.com/cscs-ci/recipes/-/raw/master/templates/v2/.ci-ext.yml'
  - local: 'ci/cscs-ci-ext-config.yml'

variables:  # Default values for base variables (can be overriden in jobs definitions)
  CUDA_VERSION: '12.6.2'
  ROCM_VERSION: '6.2.4'
  UBUNTU_VERSION: '24.04'
  UV_VERSION: '0.6.12'
  GT4PY_GITHUB_PATH: 'gridtools/gt4py'
  PYTHON_VERSIONS: ['3.10', '3.13']

stages:
  - build
  - test

# -- Build stage --
.build_base_common:
  stage: build
  # Default variables for base image builds
  variables:
    BASE_IMAGE: docker.io/ubuntu:${UBUNTU_VERSION}
    # CSCS_REBUILD_POLICY: 'always' => rebuild even if target tag exists already
    CSCS_REBUILD_POLICY: if-not-exists  # default, i.e. we could also skip the variable
    DOCKERFILE: ci/Dockerfile
    # We pass the build arguments to the Dockerfile as a JSON array of names.
    # The actual values will be taken from environment variables with the same
    # names, if they exist, or otherwise the defaults in the Dockerfile will be used.
    # To override the defaults, just define these variables in the actual job.
    DOCKER_BUILD_ARGS: >
      '["BASE_IMAGE", "CACHE_DIR", "EXTRA_APTGET", "EXTRA_UV_ENV_VARS", "EXTRA_UV_PIP_ARGS",
        "EXTRA_UV_SYNC_ARGS", "GT4PY_REPO", "PY_VERSION", "UV_VERSION", "WORKDIR_PATH" ]'
  before_script:
    # We create a tag that depends on the SHA value of ci/base.Dockerfile,
    # the docker build arguments (since we use a parameterized Docker file),
    # and the contents of the `uv.lock` file (which contains the version of
    # python packages used in the base image).
    - DOCKER_TAG=`echo "$(cat ${DOCKERFILE}) ${DOCKER_BUILD_ARGS} $(cat uv.lock)" | sha256sum | head -c 16`
    - export GT4PY_IMAGE_PREFIX=${CSCS_REGISTRY_PATH}/public/${ARCH}/base/gt4py-ci:${DOCKER_TAG}
    - echo "GT4PY_IMAGE_PREFIX=${GT4PY_IMAGE_PREFIX}" >> base.env
    - export PERSIST_IMAGE_NAME=${GT4PY_IMAGE_PREFIX}-${PY_VERSION}
    # Get the information of the current branch and PR from GitHub
    - echo "CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH}"
    - export GITHUB_PR="${CI_COMMIT_BRANCH#__CSCSCI__pr}"
    - curl https://api.github.com/repos/${GT4PY_GITHUB_PATH}/pulls/${GITHUB_PR} 2>/dev/null > gh_pull.json
    - echo "GITHUB_PR=${GITHUB_PR}" >> base.env
    - echo "GIT_TARGET_BRANCH=$(jq -r '.base.ref' gh_pull.json)" >> base.env
    - echo "GIT_CURRENT_BRANCH=$(jq -r '.head.ref' gh_pull.json)" >> base.env

  artifacts:
    reports:
      dotenv: base.env

.build_with_cuda_extra:
  variables:
    BASE_IMAGE: docker.io/nvidia/cuda:${CUDA_VERSION}-devel-ubuntu${UBUNTU_VERSION}
    EXTRA_UV_SYNC_ARGS: "--extra cuda12"

# .build_with_rocm_extra:
#   variables:
#     BASE_IMAGE: docker.io/rocm/dev-ubuntu-${UBUNTU_VERSION}:${ROCM_VERSION}-complete
#     EXTRA_UV_SYNC_ARGS: "--extra rocm6_0"
#     EXTRA_UV_ENV_VARS: "CUPY_INSTALL_USE_HIP=1 HCC_AMDGPU_TARGET=gfx90a"

build_cscs_gh200:
  extends:
    - .container-builder-cscs-gh200
    - .build_base_common
    - .build_with_cuda_extra
  parallel:
    matrix:
      - PY_VERSION: ${PYTHON_VERSIONS}

# .build_base_cscs_amd_rocm:
#   extends:
#     - .container-builder-cscs-zen2
#     - .build_base_common
#     - .build_with_rocm_extra

# -- Test stage --
.test_base:
  stage: test
  image: ${GT4PY_IMAGE_PREFIX}-${PY_VERSION}
  variables:
    GT4PY_REPO: https://github.com/${GT4PY_GITHUB_PATH}
    CSCS_CUDA_MPS: 1
    SLURM_JOB_NUM_NODES: 1
    SLURM_TIMELIMIT: 5
  parallel:
    matrix:
      - SUBPACKAGE: [cartesian]
        VARIANT: ["internal", "dace"]
        SUBVARIANT: ["cuda12", "cpu"]
        PY_VERSION: ${PYTHON_VERSIONS}
      - SUBPACKAGE: eve
        PY_VERSION: ${PYTHON_VERSIONS}
      - SUBPACKAGE: next
        VARIANT: ["internal", "dace"]
        SUBVARIANT: ["cuda12", "cpu"]
        DETAIL: ["nomesh", "atlas"]
        PY_VERSION: ${PYTHON_VERSIONS}
      - SUBPACKAGE: [storage]
        VARIANT: ["cuda12", "cpu"]
        PY_VERSION: ${PYTHON_VERSIONS}
  rules:
    - if: $SUBPACKAGE == 'next' && $VARIANT == 'dace' && $DETAIL == 'nomesh'
      variables:
        # TODO: investigate why the dace tests seem to hang with multiple jobs
        GT4PY_BUILD_JOBS: 1
        SLURM_TIMELIMIT: "00:15:00"
    - when: on_success
  script:
    # Since the image does not contain the repo, we need to clone before running the tests
    - mkdir -p "${WORKDIR}/gt4py" && git clone --depth 1 --branch "${GIT_CURRENT_BRANCH}" "${GT4PY_REPO}" "${WORKDIR}/gt4py"
    - export NOX_SESSION_ARGS="${VARIANT:+($VARIANT}${SUBVARIANT:+, $SUBVARIANT}${DETAIL:+, $DETAIL}${VARIANT:+)}"
    - cd "${WORKDIR}/gt4py" && nox -s "test_${SUBPACKAGE}-${PY_VERSION}${NOX_SESSION_ARGS}"

test_cscs_gh200:
  extends:
    - .container-runner-santis-gh200
    - .test_base
  variables:
    GT4PY_BUILD_JOBS: 8
    # Limit test parallelism to avoid "OSError: too many open files" in the gt4py build stage.
    PYTEST_XDIST_AUTO_NUM_WORKERS: 32

# .test_cscs_amd_rocm:
#   extends:
#     - .tds-container-runner-beverin-mi200
#     - .test_base
#     - .test_matrix_job
#   variables:
#
