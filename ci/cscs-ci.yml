include:
- remote: 'https://gitlab.com/cscs-ci/recipes/-/raw/master/templates/v2/.ci-ext.yml'

.py311: &py311
  PYVERSION_PREFIX: py311
  PYVERSION: 3.11.9
.py310: &py310
  PYVERSION_PREFIX: py310
  PYVERSION: 3.10.9


stages:
- baseimage
- image
- test

.build_baseimage:
  stage: baseimage
  # we create a tag that depends on the SHA value of ci/base.Dockerfile, this way
  # a new base image is only built when the SHA of this file changes
  # If there are more dependency files that should change the tag-name of the base container
  # image, they can be added too.
  # Since the base image name is runtime dependent, we need to carry the value of it to
  # the following jobs via a dotenv file.
  before_script:
  # include build arguments in hash since we use a parameterized Docker file
  - DOCKER_TAG=`echo "$(cat $DOCKERFILE) $DOCKER_BUILD_ARGS" | sha256sum | head -c 16`
  - export PERSIST_IMAGE_NAME=$CSCS_REGISTRY_PATH/public/$ARCH/base/gt4py-ci:$DOCKER_TAG-$PYVERSION
  - echo "BASE_IMAGE_${PYVERSION_PREFIX}=$PERSIST_IMAGE_NAME" >> build.env
  artifacts:
    reports:
      dotenv: build.env
  variables:
    DOCKERFILE: ci/base.Dockerfile
    # change to 'always' if you want to rebuild, even if target tag exists already (if-not-exists is the default, i.e. we could also skip the variable)
    CSCS_REBUILD_POLICY: if-not-exists
    DOCKER_BUILD_ARGS: '["CUDA_VERSION=$CUDA_VERSION", "CUPY_PACKAGE=$CUPY_PACKAGE", "CUPY_VERSION=$CUPY_VERSION", "UBUNTU_VERSION=$UBUNTU_VERSION", "PYVERSION=$PYVERSION"]'
.build_baseimage_x86_64:
  extends: [.container-builder-cscs-zen2, .build_baseimage]
  variables:
    CUDA_VERSION: 11.4.3
    CUPY_PACKAGE: cupy-cuda11x
    CUPY_VERSION: 12.3.0 # latest version that supports cuda 11
    UBUNTU_VERSION: 20.04  # 22.04 hangs on daint in some tests for unknown reasons.
.build_baseimage_aarch64:
  extends: [.container-builder-cscs-gh200, .build_baseimage]
  variables:
    CUDA_VERSION: 12.6.2
    CUPY_PACKAGE: cupy-cuda12x
    CUPY_VERSION: 13.3.0
    UBUNTU_VERSION: 22.04

# build_py311_baseimage_x86_64:
#   extends: .build_baseimage_x86_64
#   variables:
#     <<: *py311
build_py311_baseimage_aarch64:
  extends: .build_baseimage_aarch64
  variables:
    <<: *py311

# build_py310_baseimage_x86_64:
#   extends: .build_baseimage_x86_64
#   variables:
#     <<: *py310
build_py310_baseimage_aarch64:
  extends: .build_baseimage_aarch64
  variables:
    <<: *py310


.build_image:
  stage: image
  variables:
    # make sure we use a unique name here, otherwise we could create a race condition, when multiple pipelines
    # are running.
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/public/$ARCH/gt4py/gt4py-ci:$CI_COMMIT_SHA-$PYVERSION
    DOCKERFILE: ci/checkout.Dockerfile
    DOCKER_BUILD_ARGS: '["PYVERSION=$PYVERSION", "BASE_IMAGE=${BASE_IMAGE_${PYVERSION_PREFIX}}"]'
.build_image_x86_64:
  extends: [.container-builder-cscs-zen2, .build_image]
.build_image_aarch64:
  extends: [.container-builder-cscs-gh200, .build_image]

# build_py311_image_x86_64:
#   extends: .build_image_x86_64
#   needs: [build_py311_baseimage_x86_64]
#   variables:
#     <<: *py311
build_py311_image_aarch64:
  extends: .build_image_aarch64
  needs: [build_py311_baseimage_aarch64]
  variables:
    <<: *py311

# build_py310_image_x86_64:
#   extends: .build_image_x86_64
#   needs: [build_py310_baseimage_x86_64]
#   variables:
#     <<: *py310
build_py310_image_aarch64:
  extends: .build_image_aarch64
  needs: [build_py310_baseimage_aarch64]
  variables:
    <<: *py310


.test_helper:
  stage: test
  image: $CSCS_REGISTRY_PATH/public/$ARCH/gt4py/gt4py-ci:$CI_COMMIT_SHA-$PYVERSION
  script:
  - cd /gt4py.src
  - NOX_SESSION_ARGS="${VARIANT:+($VARIANT}${SUBVARIANT:+, $SUBVARIANT}${DETAIL:+, $DETAIL}${VARIANT:+)}"
  - nox -e "test_$SUBPACKAGE-${PYVERSION:0:4}$NOX_SESSION_ARGS"
  variables:
    CRAY_CUDA_MPS: 1
    SLURM_JOB_NUM_NODES: 1
    SLURM_TIMELIMIT: 20
    NUM_PROCESSES: auto
    PYENV_VERSION: $PYVERSION
    VIRTUALENV_SYSTEM_SITE_PACKAGES: 1
# .test_helper_x86_64:
#   extends: [.container-runner-daint-gpu, .test_helper]
#   parallel:
#     matrix:
#     - SUBPACKAGE: [cartesian, storage]
#       VARIANT: [-internal, -dace]
#       SUBVARIANT: [-cuda11x, -cpu]
#     - SUBPACKAGE: eve
#     - SUBPACKAGE: next
#       VARIANT: [-nomesh, -atlas]
#       SUBVARIANT: [-cuda11x, -cpu]
.test_helper_aarch64:
  extends: [.container-runner-santis-gh200, .test_helper]
  parallel:
    matrix:
    - SUBPACKAGE: [cartesian]
      VARIANT: ['internal', 'dace']
      SUBVARIANT: ['cuda12', 'cpu']
    - SUBPACKAGE: eve
    - SUBPACKAGE: next
      VARIANT: ['internal', 'dace']
      SUBVARIANT: ['cuda12', 'cpu']
      DETAIL: ['nomesh', 'atlas']
    - SUBPACKAGE: [storage]
      VARIANT: ['cuda12', 'cpu']
  variables:
    # Limit test parallelism to avoid "OSError: too many open files" in the gt4py build stage.
    # Another problem, observed in test stage, is that gpu tests hang in combination with CUDA MPS,
    # when high test parallelism is used.
    NUM_PROCESSES: 16

# test_py311_x86_64:
#   extends: [.test_helper_x86_64]
#   needs: [build_py311_image_x86_64]
#   variables:
#     <<: *py311
test_py311_aarch64:
  extends: [.test_helper_aarch64]
  needs: [build_py311_image_aarch64]
  variables:
    <<: *py311

# test_py310_x86_64:
#   extends: [.test_helper_x86_64]
#   needs: [build_py310_image_x86_64]
#   variables:
#     <<: *py310
test_py310_aarch64:
  extends: [.test_helper_aarch64]
  needs: [build_py310_image_aarch64]
  variables:
    <<: *py310
