#
# GT4Py - GridTools Framework
#
# Copyright (c) 2014-2024, ETH Zurich
# All rights reserved.
#
# Please, refer to the LICENSE file in the root directory.
# SPDX-License-Identifier: BSD-3-Clause
#

include:
  - remote: 'https://gitlab.com/cscs-ci/recipes/-/raw/master/templates/v2/.ci-ext.yml'
  - local: 'ci/cscs-ci-ext-config.yml'

variables:  # Default values for base variables (can be overriden in jobs definitions)
  CUDA_VERSION: '12.6.2'
  ROCM_VERSION: '6.2.4'
  UBUNTU_VERSION: '24.04'
  UV_VERSION: '0.6.12'

.test_python_versions: &test_python_versions ['3.10', '3.13']

stages:
  - build
  - test

# -- Build stage --
# The build job creates a the base image for the CSCS CI only if the external
# dependencies change. The actual repository is cloned at the test stage.
.build_common:
  stage: build
  variables:
    # jfrog.svc.cscs.ch/dockerhub/ubuntu is the cached version of docker.io/ubuntu
    BASE_IMAGE: jfrog.svc.cscs.ch/dockerhub/ubuntu:${UBUNTU_VERSION
    # CSCS_REBUILD_POLICY: 'always' => rebuild even if target tag exists already
    CSCS_REBUILD_POLICY: if-not-exists  # default, i.e. we could also skip the variable
    DOCKERFILE: ci/Dockerfile
    # We pass the build arguments to the Dockerfile as a JSON array of names.
    # The actual values will be taken from environment variables with the same
    # names, if they exist, or otherwise the defaults in the Dockerfile will be used.
    # To override the defaults, just define these variables in the actual job.
    DOCKER_BUILD_ARGS: '["BASE_IMAGE", "CACHE_DIR", "EXTRA_APTGET", "EXTRA_UV_ENV_VARS", "EXTRA_UV_PIP_ARGS", "EXTRA_UV_SYNC_ARGS", "PY_VERSION", "UV_VERSION", "WORKDIR_PATH" ]'
  before_script:
    # We create a tag that depends on the SHA value of ci/Dockerfile,
    # the docker build arguments since the Docker file is heavily parameterized,
    # and the contents of the `uv.lock` with the python dependencies versions.
    - GT4PY_IMAGE_PREFIX=${CSCS_REGISTRY_PATH}/public/${ARCH}/base/gt4py-ci
    - echo "GT4PY_IMAGE_PREFIX=${GT4PY_IMAGE_PREFIX}" >> build.env
    - DOCKER_BUILD_ARGS_VALUES=`for var in $(echo "$DOCKER_BUILD_ARGS" | jq -r '.[]'); do echo "$var=${!var}"; done`
    - DOCKER_TAG=`echo "$(cat ${DOCKERFILE}) ${DOCKER_BUILD_ARGS_VALUES} $(cat uv.lock)" | sha256sum | head -c 16`
    - echo "DOCKER_TAG-${PY_VERSION}=${DOCKER_TAG}" >> build.env
    - export PERSIST_IMAGE_NAME=${GT4PY_IMAGE_PREFIX}-${PY_VERSION}:${DOCKER_TAG}
    - echo "PERSIST_IMAGE_NAME=${PERSIST_IMAGE_NAME}"
    # Uncomment the following line to see the environment variables for debugging 
    # - env | sort 
  parallel:
    matrix:
      - PY_VERSION: *test_python_versions
  artifacts:
    reports:
      dotenv: build.env

.build_extra_cuda:
  variables:
    # jfrog.svc.cscs.ch/dockerhub/nvidia is the cached version of docker.io/nvidia
    BASE_IMAGE: jfrog.svc.cscs.ch/dockerhub/nvidia/cuda:${CUDA_VERSION}-devel-ubuntu${UBUNTU_VERSION}
    EXTRA_UV_SYNC_ARGS: "--extra cuda12"

# TODO: rocm steps are in draft state for now to show how to add support in the future
# .build_extra_rocm:
#   variables:
#     # jfrog.svc.cscs.ch/dockerhub/rocm is the cached version of docker.io/rocm
#     BASE_IMAGE: jfrog.svc.cscs.ch/dockerhub/rocm/dev-ubuntu-${UBUNTU_VERSION}:${ROCM_VERSION}-complete
#     EXTRA_UV_SYNC_ARGS: "--extra rocm6_0"
#     EXTRA_UV_ENV_VARS: "CUPY_INSTALL_USE_HIP=1 HCC_AMDGPU_TARGET=gfx90a"

build_cscs_gh200:
  extends:
    - .container-builder-cscs-gh200
    - .build_common
    - .build_extra_cuda

# .build_cscs_amd_rocm:
#   extends:
#     - .container-builder-cscs-zen2
#     - .build_common
#     - .build_extra_rocm

# -- Test stage --
.test_common:
  stage: test
  image: ${GT4PY_IMAGE_PREFIX}-${PY_VERSION}:${DOCKER_TAG-${PY_VERSION}}
  variables:
    CSCS_CUDA_MPS: 1
    SLURM_GPUS_PER_NODE: 4
    SLURM_JOB_NUM_NODES: 1
    SLURM_TIMELIMIT: 5
  parallel:
    matrix:
      - SUBPACKAGE: [cartesian]
        VARIANT: ["internal", "dace"]
        SUBVARIANT: ["cuda12", "cpu"]
        PY_VERSION: *test_python_versions
      - SUBPACKAGE: eve
        PY_VERSION: *test_python_versions
      - SUBPACKAGE: next
        VARIANT: ["internal", "dace"]
        SUBVARIANT: ["cuda12", "cpu"]
        DETAIL: ["nomesh", "atlas"]
        PY_VERSION: *test_python_versions
      - SUBPACKAGE: [storage]
        VARIANT: ["cuda12", "cpu"]
        PY_VERSION: *test_python_versions
  rules:
    - if: $SUBPACKAGE == 'next' && $VARIANT == 'dace' && $DETAIL == 'nomesh'
      variables:
        # TODO: investigate why the dace tests seem to hang with multiple jobs
        GT4PY_BUILD_JOBS: 1
        SLURM_TIMELIMIT: "00:15:00"
    - when: on_success
  script:
    # Since the image does not contain the repo, we need to clone it before running the tests
    # for git>=2.49: mkdir -p "${WORKDIR}/gt4py" && git clone --depth 1 --revision "${CI_COMMIT_SHA}" "${CSCS_CI_ORIG_CLONE_URL}" "${WORKDIR}/gt4py"
    - mkdir -p "${WORKDIR}/gt4py" && git clone --depth 1 "${CSCS_CI_ORIG_CLONE_URL}" "${WORKDIR}/gt4py"
    - cd "${WORKDIR}/gt4py" && git fetch --depth 1 origin "${CI_COMMIT_SHA}" && git checkout "${CI_COMMIT_SHA}"
    - export NOX_SESSION_ARGS="${VARIANT:+($VARIANT}${SUBVARIANT:+, $SUBVARIANT}${DETAIL:+, $DETAIL}${VARIANT:+)}"
    - cd "${WORKDIR}/gt4py" && nox -s "test_${SUBPACKAGE}-${PY_VERSION}${NOX_SESSION_ARGS}"

test_cscs_gh200:
  extends:
    - .container-runner-santis-gh200
    - .test_common
  variables:
    GT4PY_BUILD_JOBS: 8
    # Limit test parallelism to avoid "OSError: too many open files" in the gt4py build stage.
    PYTEST_XDIST_AUTO_NUM_WORKERS: 32

# .test_cscs_amd_rocm:
#   extends:
#     - .tds-container-runner-beverin-mi200
#     - .test_common
#   variables:
#   variables:
#     GT4PY_BUILD_JOBS: 8
#     # Limit test parallelism to avoid "OSError: too many open files" in the gt4py build stage.
#     PYTEST_XDIST_AUTO_NUM_WORKERS: 32
